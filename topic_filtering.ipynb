{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_filtering.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/shaifuss/data_science_seminar/blob/master/topic_filtering.ipynb",
      "authorship_tag": "ABX9TyOhaqLCd20MQIjD2CbaV4Ja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaifuss/data_science_seminar/blob/master/topic_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-vPFvziHYMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "2fe0aa3a-865a-4246-c624-1217fb203ee5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "!pip install pyspellchecker -q\n",
        "!pip install sentence-transformers -q\n",
        "\n",
        "workdir = r'/content/drive/My Drive/Data Science Class'\n",
        "PERSIST_INTERVAL = 30 # in minutes\n",
        "\n",
        "if not os.path.exists('review_photos'):\n",
        "    if os.path.exists('data_science_seminar'):\n",
        "        %cd data_science_seminar\n",
        "    else:\n",
        "        !git clone https://github.com/shaifuss/data_science_seminar.git\n",
        "        %cd data_science_seminar\n",
        "if (not os.path.exists('yelp_academic_dataset_business.json')) or (not os.path.exists('yelp_academic_dataset_review.json')):\n",
        "    kaggle_path = os.path.expanduser('~/.kaggle')\n",
        "    kaggle_json_path = os.path.join(kaggle_path, 'kaggle.json')\n",
        "    if not os.path.exists(kaggle_json_path):\n",
        "        from getpass import getpass\n",
        "        kaggle_json = getpass('Insert kaggle.json:')\n",
        "        os.makedirs(kaggle_path, exist_ok=True)\n",
        "        with open(kaggle_json_path, 'w') as f:\n",
        "            f.write(kaggle_json)\n",
        "        os.chmod(kaggle_json_path, 0o600)\n",
        "    !kaggle datasets download yelp-dataset/yelp-dataset\n",
        "    !unzip yelp-dataset.zip yelp_academic_dataset_business.json yelp_academic_dataset_review.json\n",
        "    !rm yelp-dataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9MB 6.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 3.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 778kB 19.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 43.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 33.6MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'data_science_seminar'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 23677 (delta 17), reused 9 (delta 2), pack-reused 23643\u001b[K\n",
            "Receiving objects: 100% (23677/23677), 1.66 GiB | 9.14 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Checking out files: 100% (14964/14964), done.\n",
            "/content/data_science_seminar\n",
            "Insert kaggle.json:··········\n",
            "Downloading yelp-dataset.zip to /content/data_science_seminar\n",
            "100% 4.47G/4.48G [01:48<00:00, 24.9MB/s]\n",
            "100% 4.48G/4.48G [01:48<00:00, 44.4MB/s]\n",
            "Archive:  yelp-dataset.zip\n",
            "  inflating: yelp_academic_dataset_business.json  \n",
            "  inflating: yelp_academic_dataset_review.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyS9X2QrgrTF",
        "colab_type": "text"
      },
      "source": [
        "In this section we aim to identify distinct topics discussed in the corpus of pizza review texts. Once topics are identified, reviews that do not contain food-related topics can be filtered out. This has the potential to improve the image classification in the next stage by weeding out irrelevent samples - where reviewers didn't base their scores on the pizza. \n",
        "\n",
        "This will be achieved by building a topic model that categorizes the information present in each review. A topic can be modeled as a set of words that are all related. For instance, we might say that [noise, smell, music, dirt, lighting] reflects the topic of restaurant atmosphere.  \n",
        "\n",
        "The first algorithm we will utilize is latent Dirichlet allocation. The premise of LDA (Biel et al., 2003) is that documents with similar topics use similar words. The algorithm aims to discover groups of words the occur frequently occur together in the same document. A topic is modeled as a probability distribution over words. Moreover, a document can be modeled as a probability distribution over different topics. \n",
        "\n",
        "Thus, the algorithm works as follows:\n",
        "\n",
        "1.   Remove unimportant words and set how many topics to find.\n",
        "2.   Randomly assign each word in each document to a random topic\n",
        "3.   For each document,\n",
        ">a. choose a topic, assuming all others are allocated correctly\n",
        "\n",
        ">>i. calculate the topic distribution within the document:  p(topic | document)\n",
        "\n",
        ">>ii. calculate the word distribution within the topic: p(word | topic)\n",
        "\n",
        ">> iii. multiply i and ii together and assign words to new topics based on the result\n",
        "\n",
        "4. terminate when there are no new assignments\n",
        "\n",
        "The LDA model is finetuned by several parameters:\n",
        "Alpha reflects how many topics are in a given document (higher values lead to more topics per document in the model)\n",
        "Beta reflects how many words are in a given topic (higher values lead to more words per topic in the model). In this implementation, the model is set to learn these values automatically.\n",
        "\n",
        "We compare the pure LDA model with a hybrid version that utilizes sentence embeddings of the review texts crafted by BERT (Devlin et al., 2018). Inspiration for this hybrid model comes from https://blog.insightdatascience.com/contextual-topic-identification-4291d256a032.\n",
        "\n",
        "BERT is a pretrained language model from researchers at Google that utilizes a multiheaded transformer ANN architecture to craft word vectors that learns to capture the meaning of words from the context in which they are found. BERT and its successors have acheived impressive performance on language understatnding tasks like question answering and others. \n",
        "\n",
        "The hybrid model attempted here fuses the topic probability vector from LDA with the review text embedding from BERT to create a hybrid sample. Clustering is then performed to distinguish different topics in the corpus. The most frequent words in the cluster become the topic. \n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di_BNmLcN5Bv",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing is necessary to create a universal vocabulary for the corpus. Each text is first processed at the string level and then at the word level. \n",
        "\n",
        "Examples:\n",
        "1. fix typos and missing spaces\n",
        "2. remove punctuation, capitalization, and numbers\n",
        "3. remove unimportant words (stopwords)\n",
        "4. stem words so that a fair comparison can be made (for example, salted and salty both become salt)\n",
        "\n",
        "Due to constraints on time and computational resources, a sample of 58993 pizza reviews was used out of nearly 480000 in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfst91OkIcNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1740fe15-d46e-40fa-87d5-262e45219119"
      },
      "source": [
        "# loading reviews into dataframe and peak at the data\n",
        "def load_reviews():\n",
        "  with open(r'/content/drive/My Drive/Data Science Class/pizza_reviews.json', 'r') as f:\n",
        "    pizza_reviews = json.load(f)\n",
        "  return pizza_reviews\n",
        "review_list = load_reviews()\n",
        "print(\"Total pizzaria reviews: {}\".format(len(review_list)))\n",
        "review_df = pd.DataFrame(review_list)\n",
        "\n",
        "text_df = review_df[['review_id', 'text']].copy()\n",
        "text_df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total pizzaria reviews: 479792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mM8i91yWP1QbImEvz5ds0w</td>\n",
              "      <td>In the heart of Chinatown, I discovered it enr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>09qxjFi4abaW66JeSLazuQ</td>\n",
              "      <td>Was a Chicago style deep dish.  Homemade type ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>K-wdPGHbErfxbKK6PetrmA</td>\n",
              "      <td>First time eating there and everything was so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jkVxX4ieJwVRO9n4E8tNMw</td>\n",
              "      <td>More than just  Pizza. This location is small ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lb9r62Qlu12ZB909CbFeOQ</td>\n",
              "      <td>I ordered a pizza at 4:49. Got an email that s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                review_id                                               text\n",
              "0  mM8i91yWP1QbImEvz5ds0w  In the heart of Chinatown, I discovered it enr...\n",
              "1  09qxjFi4abaW66JeSLazuQ  Was a Chicago style deep dish.  Homemade type ...\n",
              "2  K-wdPGHbErfxbKK6PetrmA  First time eating there and everything was so ...\n",
              "3  jkVxX4ieJwVRO9n4E8tNMw  More than just  Pizza. This location is small ...\n",
              "4  Lb9r62Qlu12ZB909CbFeOQ  I ordered a pizza at 4:49. Got an email that s..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpkiPLh-NzPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "4d8ae62d-4143-41e7-dbff-381b3df0cdd2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import re\n",
        "\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f69KGrPSNRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regex_filter(sentence):\n",
        "    # fix missing delimiter - i.e deepDishPizza\n",
        "    sentence = re.sub(r'([a-z])([A-Z])', r'\\1\\. \\2', sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r'&gt|&lt', ' ', sentence)\n",
        "    # fix letter repetition (if more than 2)\n",
        "    sentence = re.sub(r'([a-z])\\1{2,}', r'\\1', sentence)\n",
        "    # fix non-word repetition (if more than 1)\n",
        "    sentence = re.sub(r'([\\W+])\\1{1,}', r'\\1', sentence)\n",
        "    # string * as delimiter\n",
        "    sentence = re.sub(r'\\*|\\W\\*|\\*\\W', '. ', sentence)\n",
        "    # xxx[?!]. -- > xxx.\n",
        "    sentence = re.sub(r'\\W+?\\.', '.', sentence)\n",
        "    # [.?!] --> [.?!] xxx\n",
        "    sentence = re.sub(r'(\\.|\\?|!)(\\w)', r'\\1 \\2', sentence)\n",
        "    # fix phrase repetition\n",
        "    sentence = re.sub(r'(.{2,}?)\\1{1,}', r'\\1', sentence)\n",
        "\n",
        "    return sentence.strip()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bljAxTQuNLZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove numbers and punctuation marks\n",
        "def filter_punctuation(word_list):\n",
        "    return [word for word in word_list if word.isalpha()]\n",
        "\n",
        "# remove unimportant connective words such as \"and\", \"the\", etc\n",
        "def filter_stopwords(word_list):\n",
        "  return [word for word in word_list if word not in stopwords.words('english')]\n",
        "\n",
        "# keep only nouns\n",
        "def retain_nouns(word_list):\n",
        "    return [word for (word, pos) in nltk.pos_tag(word_list) if pos[:2] in ['NN']]\n",
        "\n",
        "# normlize for part of speech\n",
        "def stem_words(word_list):\n",
        "  ps = PorterStemmer()\n",
        "  return [ps.stem(word) for word in word_list]\n",
        "\n",
        "def fix_spelling(word_list):\n",
        "  spell = SpellChecker()\n",
        "  return [spell.correction(word) for word in word_list]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23SUE1RhVN83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_words(text):\n",
        "  word_list = word_tokenize(text)\n",
        "  word_list = filter_punctuation(word_list)\n",
        "  word_list = fix_spelling(word_list) \n",
        "  word_list = filter_stopwords(word_list)\n",
        "  word_list = retain_nouns(word_list)\n",
        "  return stem_words(word_list)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRmw52otQ4cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "def preprocess(reviews, samp_size=None):\n",
        "  if not samp_size:\n",
        "        samp_size = 1000\n",
        "\n",
        "  start = time.time()\n",
        "  print('Stage 1: Preprocess raw review texts')\n",
        "  texts = []  \n",
        "  token_lists = []  \n",
        "  idx_in = []\n",
        "  indicies = np.random.choice(len(reviews), samp_size)\n",
        "  for i in tqdm(indicies):\n",
        "      text = regex_filter(reviews[i])\n",
        "      token_list = preprocess_words(text)\n",
        "      if token_list:\n",
        "        idx_in.append(i)\n",
        "        texts.append(text)\n",
        "        token_lists.append(token_list)\n",
        "         \n",
        "  end = time.time()\n",
        "  print(\"Preprocessing {} reviews took {} minutes\".format(len(indicies), str((end - start)/60)))\n",
        "  return texts, token_lists, idx_in\n",
        "  "
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXvFzyNtN0gr",
        "colab_type": "text"
      },
      "source": [
        "For the hybrid model, BERT outputs sentence-level encodings of length 768 (the first output vector corresponding to the CLS token passed in at the start of each text). An LDA vector contains a probability value in range [0.0, 1.0] for each possible topic. The LDA and BERT outputs are concatenated together and clustering is performed on the resulting high-dimension vectors (the default algorithm used here is KMeans). Since the BERT vectors are much larger that the LDA vectors, scaling is performed on the LDA vectors to even out their relative importance. \n",
        "\n",
        "In an attempt to improve the clustering, dimensionality reduction is performed. An autoencoder is trained on the LDA+BERT vectors. Once training is complete, the middle hidden layer of length 32 is taken as a representation of the original data. This achieves compression of at least 25x. \n",
        "\n",
        "Clustering is performed on the compressed vectors. After clustering, topics are constructed from the top 5 most frequent words in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP_Yl6tIaO2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class Autoencoder:\n",
        "    \"\"\"\n",
        "    Autoencoder for learning latent space representation\n",
        "    architecture simplified for only one hidden layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=32, activation='relu', epochs=200, batch_size=128):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.activation = activation\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.autoencoder = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "        self.his = None\n",
        "\n",
        "    def _compile(self, input_dim):\n",
        "        \"\"\"\n",
        "        compile the computational graph\n",
        "        \"\"\"\n",
        "        input_vec = Input(shape=(input_dim,))\n",
        "        encoded = Dense(self.latent_dim, activation=self.activation)(input_vec)\n",
        "        decoded = Dense(input_dim, activation=self.activation)(encoded)\n",
        "        self.autoencoder = Model(input_vec, decoded)\n",
        "        self.encoder = Model(input_vec, encoded)\n",
        "        encoded_input = Input(shape=(self.latent_dim,))\n",
        "        decoder_layer = self.autoencoder.layers[-1]\n",
        "        self.decoder = Model(encoded_input, self.autoencoder.layers[-1](encoded_input))\n",
        "        self.autoencoder.compile(optimizer='adam', loss=keras.losses.mean_squared_error)\n",
        "\n",
        "    def fit(self, X):\n",
        "        if not self.autoencoder:\n",
        "            self._compile(X.shape[1])\n",
        "        X_train, X_test = train_test_split(X)\n",
        "        self.his = self.autoencoder.fit(X_train, X_train,\n",
        "                                        epochs=200,\n",
        "                                        batch_size=128,\n",
        "                                        shuffle=True,\n",
        "                                        validation_data=(X_test, X_test), verbose=0)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guIiZR7zi4rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from gensim import corpora\n",
        "import gensim\n",
        "\n",
        "# define model object\n",
        "class Topic_Model:\n",
        "    def __init__(self, method, k=4):\n",
        "        \"\"\"\n",
        "        :param k: number of topics\n",
        "        :param method: method chosen for the topic model\n",
        "        \"\"\"\n",
        "        if method not in {'LDA', 'BERT', 'LDA_BERT'}:\n",
        "            raise Exception('Invalid method!')\n",
        "        self.k = k\n",
        "        self.dictionary = None\n",
        "        self.corpus = None\n",
        "        self.cluster_model = None\n",
        "        self.ldamodel = None\n",
        "        self.vec = {}\n",
        "        self.gamma = 250  # parameter for reletive importance of lda\n",
        "        self.method = method\n",
        "        self.AE = None\n",
        "        self.id = method + '_' + str(round(time.time(),0))\n",
        "\n",
        "    def vectorize(self, sentences, token_lists, method=None):\n",
        "        \"\"\"\n",
        "        Get vector representations from selected methods\n",
        "        \"\"\"\n",
        "        # Default method\n",
        "        if method is None:\n",
        "            method = self.method\n",
        "\n",
        "        # turn tokenized documents into a id <-> term dictionary\n",
        "        self.dictionary = corpora.Dictionary(token_lists)\n",
        "        # convert tokenized documents into a document-term matrix\n",
        "        self.corpus = [self.dictionary.doc2bow(text) for text in token_lists]\n",
        "\n",
        "        if method == 'LDA':\n",
        "            print('Getting vector representations for LDA ...')\n",
        "            if not self.ldamodel:\n",
        "                self.ldamodel = gensim.models.ldamodel.LdaModel(self.corpus, num_topics=self.k, id2word=self.dictionary,\n",
        "                                                                passes=20, alpha='auto', )\n",
        "\n",
        "            def get_vec_lda(model, corpus, k):\n",
        "                \"\"\"\n",
        "                Get the LDA vector representation (probabilistic topic assignments for all documents)\n",
        "                :return: vec_lda with dimension: (n_doc * n_topic)\n",
        "                \"\"\"\n",
        "                n_doc = len(corpus)\n",
        "                vec_lda = np.zeros((n_doc, k))\n",
        "                for i in range(n_doc):\n",
        "                    # get the distribution for the i-th document in corpus\n",
        "                    for topic, prob in model.get_document_topics(corpus[i]):\n",
        "                        vec_lda[i, topic] = prob\n",
        "\n",
        "                return vec_lda\n",
        "\n",
        "            vec = get_vec_lda(self.ldamodel, self.corpus, self.k)\n",
        "            return vec\n",
        "\n",
        "        elif method == 'BERT':\n",
        "\n",
        "            print('Getting vector representations for BERT ...')\n",
        "            from sentence_transformers import SentenceTransformer\n",
        "            model = SentenceTransformer('bert-base-nli-max-tokens')\n",
        "            vec = np.array(model.encode(sentences, show_progress_bar=True))\n",
        "            return vec\n",
        "\n",
        "        #         elif method == 'LDA_BERT':\n",
        "        else: \n",
        "            vec_lda = self.vectorize(sentences, token_lists, method='LDA')\n",
        "            vec_bert = self.vectorize(sentences, token_lists, method='BERT')\n",
        "            vec_ldabert = np.c_[vec_lda * self.gamma, vec_bert]\n",
        "            self.vec['LDA_BERT_FULL'] = vec_ldabert\n",
        "            if not self.AE:\n",
        "                self.AE = Autoencoder()\n",
        "                print('Fitting Autoencoder ...')\n",
        "                self.AE.fit(vec_ldabert)\n",
        "            vec = self.AE.encoder.predict(vec_ldabert)\n",
        "            return vec\n",
        "\n",
        "    def fit(self, sentences, token_lists, method=None, m_clustering=None):\n",
        "        \"\"\"\n",
        "        Fit the topic model for selected method given the preprocessed data\n",
        "        :docs: list of documents, each doc is preprocessed as tokens\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # Default method\n",
        "        if method is None:\n",
        "            method = self.method\n",
        "        # Default clustering method\n",
        "        if m_clustering is None:\n",
        "            m_clustering = KMeans\n",
        "\n",
        "        # turn tokenized documents into a id <-> term dictionary\n",
        "        if not self.dictionary:\n",
        "            self.dictionary = corpora.Dictionary(token_lists)\n",
        "            # convert tokenized documents into a document-term matrix\n",
        "            self.corpus = [self.dictionary.doc2bow(text) for text in token_lists]\n",
        "\n",
        "        ####################################################\n",
        "        #### Getting ldamodel or vector representations ####\n",
        "        ####################################################\n",
        "\n",
        "        if method == 'LDA':\n",
        "            if not self.ldamodel:\n",
        "                print('Fitting LDA ...')\n",
        "                self.ldamodel = gensim.models.ldamodel.LdaModel(self.corpus, num_topics=self.k, id2word=self.dictionary\n",
        "                                                                , alpha='auto', eta='auto', minimum_probability=0.3)\n",
        "        else:\n",
        "            print('Clustering embeddings ...')\n",
        "            self.cluster_model = m_clustering(self.k)\n",
        "            self.vec[method] = self.vectorize(sentences, token_lists, method)\n",
        "            self.cluster_model.fit(self.vec[method])\n",
        "\n",
        "    def predict(self, sentences, token_lists, out_of_sample=True):\n",
        "        \"\"\"\n",
        "        Predict topics for new_documents\n",
        "        \"\"\"\n",
        "        # Default as False\n",
        "        out_of_sample = out_of_sample is not None\n",
        "\n",
        "        print(\"Predicting...\")\n",
        "        if out_of_sample:\n",
        "            corpus = [self.dictionary.doc2bow(text) for text in token_lists]\n",
        "            if self.method != 'LDA':\n",
        "                vec = self.vectorize(sentences, token_lists)\n",
        "                print(vec)\n",
        "        else:\n",
        "            corpus = self.corpus\n",
        "            vec = self.vec.get(self.method, None)\n",
        "\n",
        "        if self.method == \"LDA\":   # take the most prevalent topic\n",
        "            #lbs = np.array(list(map(lambda x: sorted(self.ldamodel.get_document_topics(x),\n",
        "                                                     #key=lambda x: x[1], reverse=True)[0][0], corpus)))\n",
        "            lbs = []\n",
        "            for text in corpus:\n",
        "              lbs.append(self.ldamodel.get_document_topics(text))\n",
        "        else:\n",
        "            lbs = self.cluster_model.predict(vec)\n",
        "        return lbs\n",
        "    def persist(self, workdir):\n",
        "      with open(os.path.join(workdir, \"test_\" + self.id), 'wb') as f:\n",
        "        pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0_LG2cBV8Li",
        "colab_type": "text"
      },
      "source": [
        "Coherence is used for topic model evaluation (Roder et al., 2015). As topic models produced algorithmically are sometimes not easily interpreted by humans, it is necessary to have a way to objectively measure how well the words in a topic go together. \n",
        "\n",
        "Very generally, coherence can be evaluated for a topic by first computing a Cartesian product on itself to construct pairs (excluding twin pairs). The co-occurence of each pair is checked in an external reference - a very large corpus of texts said to represent common language usage. The higher the co-occurence scores, the higher the topic coherence.\n",
        "\n",
        "A silhoutte score is used to evaluate clustering. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsan4epLeHG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.metrics import silhouette_score\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import os\n",
        "\n",
        "\n",
        "def get_topic_words_hybrid(token_lists, labels, k=None):\n",
        "    \"\"\"\n",
        "    get top words within each topic from clustering results\n",
        "    \"\"\"\n",
        "    if k is None:\n",
        "        k = len(np.unique(labels))\n",
        "    topics = ['' for _ in range(k)]\n",
        "    for i, c in enumerate(token_lists):\n",
        "        topics[labels[i]] += (' ' + ' '.join(c))\n",
        "    word_counts = list(map(lambda x: Counter(x.split()).items(), topics))\n",
        "    # get sorted word counts\n",
        "    word_counts = list(map(lambda x: sorted(x, key=lambda x: x[1], reverse=True), word_counts))\n",
        "    # get topics\n",
        "    topics = list(map(lambda x: list(map(lambda x: x[0], x[:5])), word_counts))\n",
        "    return topics\n",
        "\n",
        "def get_topic_words_lda(model):\n",
        "    return CoherenceModel.top_topics_as_word_lists(model=model.ldamodel, dictionary=model.dictionary, topn=5)\n",
        "\n",
        "def get_coherence(model, token_lists, measure='c_v'):\n",
        "    \"\"\"\n",
        "    Get model coherence from gensim.models.coherencemodel\n",
        "    :param model: Topic_Model object\n",
        "    :param token_lists: token lists of docs\n",
        "    :param topics: topics as top words\n",
        "    :param measure: coherence metrics\n",
        "    :return: coherence score\n",
        "    \"\"\"\n",
        "    if model.method == 'LDA':\n",
        "        cm = CoherenceModel(model=model.ldamodel, texts=token_lists, corpus=model.corpus, dictionary=model.dictionary,\n",
        "                            coherence=measure)\n",
        "        print(CoherenceModel.top_topics_as_word_lists(model=model.ldamodel, dictionary=model.dictionary, topn=5))\n",
        "    else:\n",
        "        topics = get_topic_words_hybrid(token_lists, model.cluster_model.labels_)\n",
        "        print(\"Topics are:\\n{}\".format(topics))\n",
        "        cm = CoherenceModel(topics=topics, texts=token_lists, corpus=model.corpus, dictionary=model.dictionary,\n",
        "                            coherence=measure)\n",
        "    return cm.get_coherence()\n",
        "\n",
        "def get_silhouette(model):\n",
        "    \"\"\"\n",
        "    Get silhouette score from model\n",
        "    :param model: Topic_Model object\n",
        "    :return: silhouette score\n",
        "    \"\"\"\n",
        "    if model.method == 'LDA':\n",
        "        return\n",
        "    lbs = model.cluster_model.labels_\n",
        "    vec = model.vec[model.method]\n",
        "    return silhouette_score(vec, lbs)\n",
        "\n",
        "def plot_proj(embedding, lbs):\n",
        "    \"\"\"\n",
        "    Plot UMAP embeddings\n",
        "    :param embedding: UMAP (or other) embeddings\n",
        "    :param lbs: labels\n",
        "    \"\"\"\n",
        "    n = len(embedding)\n",
        "    counter = Counter(lbs)\n",
        "    for i in range(len(np.unique(lbs))):\n",
        "        plt.plot(embedding[:, 0][lbs == i], embedding[:, 1][lbs == i], '.', alpha=0.5,\n",
        "                 label='cluster {}: {:.2f}%'.format(i, counter[i] / n * 100))\n",
        "    plt.legend(loc = 'best')\n",
        "    plt.grid(color ='grey', linestyle='-',linewidth = 0.25)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YNL6n9hkNoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(model):\n",
        "    \"\"\"\n",
        "    Visualize the result for the topic model by 2D embedding (UMAP)\n",
        "    :param model: Topic_Model object\n",
        "    \"\"\"\n",
        "    if model.method == 'LDA':\n",
        "        return\n",
        "    reducer = umap.UMAP()\n",
        "    print('Calculating UMAP projection ...')\n",
        "    vec_umap = reducer.fit_transform(model.vec[model.method])\n",
        "    plot_proj(vec_umap, model.cluster_model.labels_)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDekpuykvS47",
        "colab_type": "text"
      },
      "source": [
        "We hypothesize that the following four topics are relevant to pizza reviews.\n",
        "\n",
        "1. Food\n",
        "2. Service\n",
        "3. Atmosphere\n",
        "4. Value\n",
        "\n",
        "Adding +/- 1, we train models with 3, 4, and 5 topics for each method. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY2urPDtaoRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(method, ntopic, sentences, token_lists, idx_in):\n",
        "    \n",
        "  tmfile =  method + \"_\" + str(round(time.time(),0)) +'.file'\n",
        "  print(\"Starting training...\")\n",
        "  start = time.time()\n",
        "  tm = Topic_Model(method, k = ntopic)\n",
        "  tm.fit(sentences, token_lists)\n",
        "  end = time.time()\n",
        "  tm.persist(workdir)\n",
        "  print(\"Training on {} reviews took {} minutes\".format(len(sentences), str((end - start)/60)))\n",
        "  \n",
        "  return tm\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caQQy8uEoa3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dict = dict()\n",
        "\n",
        "pic_path = 'review_photos'\n",
        "pix_review_ids = [f for f in os.listdir(pic_path) if os.path.isdir(os.path.join(pic_path, f))]\n",
        "\n",
        "pic_review_df = text_df[text_df['review_id'].isin(pix_review_ids)]\n",
        "pic_review_df = pic_review_df.reset_index(drop=True)\n",
        "pic_review_df = pic_review_df.fillna('')\n",
        "reviews = pic_review_df.text\n",
        "\n",
        "sentences, token_lists, idx_in = preprocess(reviews, len(reviews) + 1)\n",
        "\n",
        "for method in [\"LDA\", \"LDA_BERT\"]:\n",
        "  for num_topics in range(3, 6):\n",
        "    tm = train(method, num_topics, sentences, token_lists, idx_in)\n",
        "    model_dict[method + \"_\" + str(num_topics)] = dict()\n",
        "    model_dict[method + \"_\" + str(num_topics)][\"model\"] = tm\n",
        "    model_dict[method + \"_\" + str(num_topics)][\"coherence\"] = get_coherence(tm, token_lists, 'c_v')\n",
        "    model_dict[method + \"_\" + str(num_topics)][\"silhouette\"] = get_silhouette(tm)\n",
        "    if method == \"LDA\":\n",
        "      model_dict[method + \"_\" + str(num_topics)][\"topics\"] = get_topic_words_lda(tm)\n",
        "    else:\n",
        "      model_dict[method + \"_\" + str(num_topics)][\"topics\"] = get_topic_words_hybrid(token_lists, tm.cluster_model.labels_, k=None)\n",
        "      visualize(tm)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph1S4BbBbGEJ",
        "colab_type": "text"
      },
      "source": [
        "Evaluation\n",
        "\n",
        "We compare the hybrid topic cluster model with a pure LDA model. The models were run multiple times with a range of values for each hyperparameter.\n",
        "\n",
        "Observations:\n",
        "1. Coherence was consistently an order of magnitude higher for the pure LDA model. \n",
        "2. Silhoutte scores improved as the LDA vectors were weighted more heavily in the hybrid model\n",
        "3. The pure LDA model produced higher quality topics as judged by two human evaluators (us). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR5CIIYosI7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "264f2d1a-c518-4ef9-e90d-e22a2c4b103b"
      },
      "source": [
        "stemmed_pizza_vocab = stem_words([\"crust\", \"slice\", \"sauce\", \"topping\", \"cheese\", \"tomato\", \"food\", \"pie\"])\n",
        "\n",
        "for method, output_dict in model_dict.items():\n",
        "  output_dict[\"scores\"] = []\n",
        "  topics = output_dict[\"topics\"]\n",
        "  for topic in topics:\n",
        "    score = 0\n",
        "    for i, word in reversed(list(enumerate(reversed(topic)))):\n",
        "      if word == \"pizza\": # most important word is worth double\n",
        "        score += (i + 1) * 2\n",
        "      elif word in stemmed_pizza_vocab:\n",
        "        score += (i + 1)\n",
        "    output_dict[\"scores\"].append(score)\n",
        "  print(\"method: {}, topic scores: {}\".format(method, model_dict[method][\"scores\"]))\n",
        "  print(\"method: {}, coherence: {}\".format(method, model_dict[method][\"coherence\"]))\n",
        "  if \"BERT\" in method:\n",
        "    print(\"method: {}, silhouette: {}\".format(method, model_dict[method][\"silhouette\"]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "method: LDA_3, topic scores: [2, 5, 16]\n",
            "method: LDA_3, coherence: 0.5643122178952032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_il3KDrXlSbT",
        "colab_type": "text"
      },
      "source": [
        "To filter reviews, take the model with the highest coherence. Then choose the topic with the highest score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UASLssNyk1T2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d956b5c0-b276-4b88-93ac-7117ef1e9552"
      },
      "source": [
        "best_method = max(model_dict, key=lambda v: model_dict[v]['coherence'])\n",
        "best_topic = max(range(len(model_dict[best_method][\"scores\"])), key=model_dict[best_method][\"scores\"].__getitem__)\n",
        "print(\"best method is {}\".format(best_method))\n",
        "print(\"best_topic is at index {}\".format(best_topic))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best method is LDA_3\n",
            "best_topic is at index 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P02iiJwSQWYI",
        "colab_type": "text"
      },
      "source": [
        "For prediction with the pure LDA model, the topics are retrieved for a given review. If the best pizza topic is not the most prominent topic in that review, our hypothesis is that discarding it will lead to improved performance for the image classifier.\n",
        "\n",
        "For prediction with the LDA+BERT version, a review is place into a cluster with the pretrained model. Similar to the pure model, we should keep the reviews that fall into the best pizza topic cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ZNfuv3QVgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8a1188f2-69de-4226-81fa-d9e8316b3747"
      },
      "source": [
        "import random\n",
        "\n",
        "print(\"There are {} reviews before filtering\".format(len(sentences)))\n",
        "topic_lists = model_dict[best_method][\"model\"].predict(sentences, token_lists, True)\n",
        "indicies = []\n",
        "for i, topic_list in enumerate(topic_lists):\n",
        "  topics = [x[0] for x in topic_list]\n",
        "  if best_topic in topics:\n",
        "    indicies.append(i)\n",
        "print(\"There are {} reviews afer filtering\".format(len(indicies)))\n",
        "\n",
        "food_based_reviews = pic_review_df[pic_review_df.index.isin(indicies)]\n",
        "print(\"Example reviews that passed the filter:\\n\")\n",
        "print(food_based_reviews.loc[random.choice(indicies), \"text\"])\n",
        "print(\"---------------------------------------------------------------\")\n",
        "print(food_based_reviews.loc[random.choice(indicies), \"text\"])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 10304 reviews before filtering\n",
            "Predicting...\n",
            "There are 6807 reviews afer filtering\n",
            "Example reviews that passed the filter:\n",
            "\n",
            "What an amazing place! My husband and I are pretty critical and we both had awesome food and service. He got the infamous gnocchi bread bowl and it lived up to its reputation. We started with try bread plate. The kale salad was so light and flavorful! I will go back there for that salad alone. Husband had the beans and greens. Could of use it with out the sausage but great non the less. I had the asparagus tagliatelle. The light lemon citrus cream sauce with asparagus was amazing. You can tell the noodles are homemade and not out of a box. We finished with the tiramisu that this Italian girl was in heaven with. Our server Ashley was very knowledgeable with the food and wine recommendations. Atmosphere and music was perfect. I can not wait  to take guests back here and show them how great this place is. A real 5 star gem !\n",
            "---------------------------------------------------------------\n",
            "Beat soppressata pizza I have had in Toronto so far! Absolutely delicious - the salami was nice and spicy and the crust was thin.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llm5vgvUzSRh",
        "colab_type": "text"
      },
      "source": [
        "If filtering alters the rating distribution of the dataset, it's more difficult to draw conclusions about it's impact on classification. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HQVmJAJ1uSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns  \n",
        "def pizza_plot(x, title, ylabel, xlabel, size):\n",
        "  x=x.sort_index()\n",
        "  plt.figure(figsize=size)\n",
        "  ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
        "  plt.title(title)\n",
        "  plt.ylabel(ylabel, fontsize=12)\n",
        "  plt.xlabel(xlabel, fontsize=12)\n",
        "\n",
        "  rects = ax.patches\n",
        "  labels = x.values\n",
        "  for rect, label in zip(rects, labels):\n",
        "      height = rect.get_height()\n",
        "      ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFk6H8S01zvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "f3ec2106-2050-4477-e309-f09db1976c77"
      },
      "source": [
        "pre_mask = review_df.review_id.isin(pic_review_df.review_id)\n",
        "pre_df = new_df = review_df[pre_mask]\n",
        "pizza_plot(pre_df['stars'].value_counts(), \"Pre-filtering Rating Distribution\", 'Review Count', 'Stars', (8,4))\n",
        "\n",
        "post_mask = review_df.review_id.isin(food_based_reviews.review_id)\n",
        "post_df = review_df[post_mask]\n",
        "pizza_plot(post_df['stars'].value_counts(), \"Post-filtering Rating Distribution\", 'Review Count', 'Stars', (8,4))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAEZCAYAAACdGfwcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwV1Z338c9XCSRqFFlFGsUFRVQWJaBZXEdFY6LJQ1RiIiDI6OgMScjjmGQmqNF5yCTRuCQajURcghqjkRiDIu4zooC2uyxRFAgKyqKgUZHf80edxmvbTV/gLt1d3/fr1a9bderUqd8tffG7dc6pKkUEZmZm1vptUe0AzMzMrDKc9M3MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcsJJ36wElPmdpBWSHpf0JUlzCrYvkPRPJTzeyZLuKVV75STpSkn/WcXjPyfpkBK19bHzLikk7V6KtlN7qyXtWqr2zOqT79O3vJC0AOgKfAisAf4KnBURq0vQ9peAycCeEbGmkWOPjoh7JZ0L7B4R39rc45ZDvfO0GphKkedJ0giy7/nFcsaYjtUTeJnsvyXpcyZwSURM28S2PhURazdivwB6RcT8jTle2vcB4IaI+O3G7mu2qXylb3nzlYjYBtgPGAj8R/0KktpsQrs7AwsaSviltonxbay689QfGAD8oALH3FTtU6z9gGnA7enHR0lV6LyblZWTvuVSRCwmu9LfB9Z3054paR4wL5UdK6lW0kpJ/yupb0NtSRoF/BY4MHXPnifpEEmLGqg7BPghcGKq+1Qq307SNZKWSFos6QJJW6ZtIyT9j6SLJb0JnJvKHiloNySdLmleivdXkpS2bSnpF5LekPSypLNS/SaTWES8BtxNlvzrjnWOpL9JelvS85K+lsr3Aq4sOA8rU/m1ki5Iy4dIWiRpnKSl6fuOLGi7o6Q/S3pL0sx0Hh6hCBHxWkRcApwL/FTSFqnN9UMrkgZJmpXaf13SRWn3h9LnyhT7gcWc9+QYSS+l8/uzguOeK+mGgu/Ws+68S7oQ+BJweTre5anO+uGC9P/EdZKWSXpF0n8UtD1C0iOSfq5sSOllSUcXc54s35z0LZck9QCOAZ4sKD4eGAz0kTQAmAj8M9AR+A0wRVK7+m1FxDXA6cCjEbFNRIxv7LgRMRX4L+DmVLdf2nQtsBbYnezK+khgdMGug4GXyLrdL2yk+WOBzwF9gROAo1L5acDRZIl7v/Q9iyKpJu1b2H39N7KEtR1wHnCDpG4R8QIfPw/tG2l2h7Rvd2AU8CtJ26dtvyLrpt8BGJ7+NtZtQBdgzwa2XULW/b8tsBtwSyo/KH22T7E/mtaLOe9fI+s12g84Dji1qQAj4kfAw2TDJttExFkNVLuM7DztChwMnAKMLNg+GJgDdAL+G7im7oeeWWOc9C1v/pSuQB8BHiRLwHX+X0Qsj4h3gTHAbyLisYj4MCImAe8BB5Q6IEldyX6AfCci1kTEUuBi4KSCan+PiMsiYm2KryETImJlRLwK3M9HV+cnkCW6RRGxAphQRFh/kvQ2sBBYCqz/IRMRf4iIv0fEuoi4maxnZNBGfOUPgPMj4oOIuIts3sCeqWfj/wDjI+KdiHgemLQR7db5e/rs0Mixd5fUKSJWR8SMptoq4rz/NP1/8yrwS2DYJsT8MelcnAT8ICLejogFwC+AbxdUeyUiro6ID8nOUzeyHydmjXLSt7w5PiLaR8TOEfEv9f4hX1iwvDMwLnWVr0w/FHoAOyqbwb06/f21BDHtDHwKWFJwrN+QXa02FFtjXitYfgfYJi3vWG//Yto6PiI+CxwC9Ca7mgRA0ikFwx4ryYZIOjXcTIPerDdZri7WzkCbTYi1vu7pc3kD20YBewAvpuGDY5toq5jjF9Z5hex8b65OZP9PvFKv7e4F6+v/e0fEO2lxG8w2wBNTzD5SeCvLQuDCiGisS/fGEh2n7ljvAZ02MHN8c26zWQLUFKz3KHbHiHhQ0rXAz4HjJe0MXA0cTtaN/6GkWqCuW3lz4lxGNsRRA8zd2FgLfI2sd2JO/Q0RMQ8YlsbGvw7cKqkjjcddzPfpATyXlnfio56GNcBWBfV22Ii23yDrldgZeL6g7cVFxGPWKF/pmzXsauB0SYOV2VrSlyV9tgRtvw70rJuUFRFLgHuAX0jaVtIWknaTdHAJjgXZuPVYSd0ltQf+fSP3/yVwhKR+wNZkyWoZQJqEt09B3deBGkltNzbI1E19G9mEua0k9SYbxy6KpK6SziIbivhBRKxroM63JHVO21am4nXp+6wjGz/fWP9X0vZpnshY4OZUXgscJGknSdvxyTsgXm/seOlc3AJcKOmz6cfW94AbGqpvViwnfbMGRMQssglwlwMryCayjShR839In29KeiItnwK0JbuqWwHcSjZGWwpXk/2oeJps4uJdZFfUHxazc0QsA64DfpzG2X8BPEqWtPYF/qeg+n1kV72vSXpjE2I9i2zy2mvA9WTPPniviX1WSloDPEM2N+IbETGxkbpDgOckrSab1HdSRLybuscvBP4nDVtszNyNO4DZZEn+L8A1AOlZATeTnffZwJ319rsEGJpm31/aQLv/StZb8BLZHJTfk00uNdtkfjiPWc6kW7uujIidqx1LUyT9FNghIjZlFr+Z1eMrfbNWTtJnJB2T7g/vTtb9fXu142qIpN6S+qYhlUFkE++aZaxmLZGTvlnrJ7L76VeQde+/APy4qhE17rNk4/pryLrGf0HWfW5mJeDufTMzs5zwlb6ZmVlOtPr79Dt16hQ9e/asdhhmZmYVM3v27DcionP98laf9Hv27MmsWbOqHYaZmTUjK1euZPTo0Tz77LNIYuLEiWy11VacfvrprF69mp49e3LjjTey7bbbsmDBAvbaay/23DN7ncMBBxzAlVdeCcCPfvQjrrvuOlasWMHq1Zv9lu6SkfRKQ+Xu3jczs9wZO3YsQ4YM4cUXX+Spp55ir732YvTo0UyYMIFnnnmGr33ta/zsZz9bX3+33XajtraW2tra9Qkf4Ctf+QqPP/54Nb7CJnHSNzOzXFm1ahUPPfQQo0aNAqBt27a0b9+euXPnctBB2QsXjzjiCP74xz822dYBBxxAt26leo5W+Tnpm5lZrrz88st07tyZkSNHMmDAAEaPHs2aNWvYe++9ueOO7A7RP/zhDyxcuPBj+wwYMICDDz6Yhx9+uFqhbzYnfTMzy5W1a9fyxBNPcMYZZ/Dkk0+y9dZbM2HCBCZOnMivf/1r9t9/f95++23ats1eIdGtWzdeffVVnnzySS666CK++c1v8tZbb1X5W2yaiiR9SXumV3HW/b0l6TuSOkiaJmle+tw+1ZekSyXNl/S0pP0K2hqe6s+T5EdzmpnZRqmpqaGmpobBgwcDMHToUJ544gl69+7NPffcw+zZsxk2bBi77bYbAO3ataNjx44A7L///uy2227MnTu30fabs4ok/YiYExH9I6I/sD/Z+7NvB84BpkdEL2B6Wgc4GuiV/sYAVwBI6kD2CNHBwCBgfN0PBTMzs2LssMMO9OjRgzlzsrcvT58+nT59+rB06VIA1q1bxwUXXMDpp58OwLJly/jww+z9VC+99BLz5s1j11035YWM1VeN7v3Dgb9FxCvAccCkVD4JOD4tHwdcF5kZQHtJ3YCjgGkRsTwiVgDTyN6aZWZmVrTLLruMk08+mb59+1JbW8sPf/hDJk+ezB577EHv3r3ZcccdGTlyJAAPPfQQffv2pX///gwdOpQrr7ySDh06AHD22WdTU1PDO++8Q01NDeeee24Vv1XTKv4YXkkTgSci4nJJKyOifSoXsCIi2ku6E5gQEY+kbdPJ3gF+CPDpiLgglf8n8G5E/LzeMcaQ9RCw00477f/KKw3ermhmZtYqSZodEQPrl1f0Sl9SW+CrfPQ+8fUi+/VRkl8gEXFVRAyMiIGdO3/igURmZma5VOkn8h1NdpX/elp/XVK3iFiSuu+XpvLFQI+C/WpS2WKyq/3C8gfKGrGZmVXUzRc/VO0QmrUTv3vQJu9b6TH9YcDkgvUpQN0M/OF89ArNKcApaRb/AcCqiFgC3A0cKWn7NIHvyFRmZmZmTajYlb6krYEjgH8uKJ4A3CJpFPAKcEIqvws4BphPNtN/JEBELJf0E2Bmqnd+RCyvQPhmZmYtXsWSfkSsATrWK3uTbDZ//boBnNlIOxOBieWI0czMrDXzE/nMzMxywknfzMwsJ5z0zczMcsJJ38zMLCec9M3MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcsJJ38zMLCec9M3MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcsJJ38zMLCec9M3MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcqJiSV9Se0m3SnpR0guSDpTUQdI0SfPS5/apriRdKmm+pKcl7VfQzvBUf56k4ZWK38zMrKWr5JX+JcDUiOgN9ANeAM4BpkdEL2B6Wgc4GuiV/sYAVwBI6gCMBwYDg4DxdT8UzMzMbMMqkvQlbQccBFwDEBHvR8RK4DhgUqo2CTg+LR8HXBeZGUB7Sd2Ao4BpEbE8IlYA04AhlfgOZmZmLV2lrvR3AZYBv5P0pKTfStoa6BoRS1Kd14Cuabk7sLBg/0WprLHyj5E0RtIsSbOWLVtW4q9iZmbWMlUq6bcB9gOuiIgBwBo+6soHICICiFIcLCKuioiBETGwc+fOpWjSzMysxatU0l8ELIqIx9L6rWQ/Al5P3fakz6Vp+2KgR8H+NamssXIzMzNrQkWSfkS8BiyUtGcqOhx4HpgC1M3AHw7ckZanAKekWfwHAKvSMMDdwJGStk8T+I5MZWZmZtaENhU81r8CN0pqC7wEjCT70XGLpFHAK8AJqe5dwDHAfOCdVJeIWC7pJ8DMVO/8iFheua9gZmbWclUs6UdELTCwgU2HN1A3gDMbaWciMLG00ZmZmbV+fiKfmZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU5ULOlLWiDpGUm1kmalsg6Spkmalz63T+WSdKmk+ZKelrRfQTvDU/15koZXKn4zM7OWrtJX+odGRP+IGJjWzwGmR0QvYHpaBzga6JX+xgBXQPYjARgPDAYGAePrfiiYmZnZhlW7e/84YFJangQcX1B+XWRmAO0ldQOOAqZFxPKIWAFMA4ZUOmgzM7OWqKikL2mHjSlvRAD3SJotaUwq6xoRS9Lya0DXtNwdWFiw76JU1lh5/bjGSJoladayZcs2IkQzM7PWq02R9eYC2zZQ/jzQocg2vhgRiyV1AaZJerFwY0SEpCiyrQ2KiKuAqwAGDhxYkjbNzMxaumK79/WJAmlbYF2xB4qIxelzKXA72Zj866nbnvS5NFVfDPQo2L0mlTVWbmZmZk3YYNKXtFDSq8BnJL1a+AcsAf5UzEEkbS3ps3XLwJHAs8AUoG4G/nDgjrQ8BTglzeI/AFiVhgHuBo6UtH2awHdkKjMzM7MmNNW9/y2yq/y7gG8XlAfwekTMKfI4XYHbJdUd8/cRMVXSTOAWSaOAV4ATUv27gGOA+cA7wEiAiFgu6SfAzFTv/IhYXmQMZmZmubbBpB8RDwJI6hQR72zqQSLiJaBfA+VvAoc3UB7AmY20NRGYuKmxmJmZ5VWxE/nWphn3/YFtCjdExCklj8rMzMxKrtikfx3QF/gz8Hr5wjEzM7NyKTbpHwXsEhEryxmMmZmZlU+xt+y9CrQrZyBmZmZWXhvTvX+HpEuo170fEfeVPCozMzMruWKT/lnp87/qlQewa+nCMTMzs3IpKulHxC7lDsTMzMzKq9pv2TMzM7MKKepKX9JCsq78T4iInUoakZmZmZVFsWP636q33g0YC9xU2nDMzMysXIod03+wfpmkB4CpwCUljsnMzMzKYHPG9N8DPMHPzMyshSh2TP/8ekVbkb0F768lj8jMzMzKotgx/R711tcAFwHXlzYcMzMzK5dix/RHljsQMzMzK69ir/SRdAhwCtAdWAxcHxH3lykuMzMzK7GiJvJJGg3cArwG3AYsASZLOq2MsZmZmVkJFXulfzZwREQ8VVcg6Wbgj8DV5QjMzMzMSqvYW/Y6As/XK5sDdChtOGZmZlYuxSb9R4CLJG0FIGlr4GfA/5YrMDMzMyutYpP+6UA/YJWk14GVaf2fN+ZgkraU9KSkO9P6LpIekzRf0s2S2qbydml9ftres6CNH6TyOZKO2pjjm5mZ5VlRST8ilkTEQWRP4PsKsEtEHBwRf9/I440FXihY/ylwcUTsDqwARqXyUcCKVH5xqoekPsBJwN7AEODXkrbcyBjMzMxyaYNJX9JOktbfox8RiyLi8YhYJGmEpJpiD5Tqfhn4bVoXcBhwa6oyCTg+LR+X1knbD0/1jwNuioj3IuJlYD4wqNgYzMzM8qypK/0fA59uZFu7tL1YvyS7C2BdWu8IrIyItWl9EdkzAEifCwHS9lWp/vryBvYxMzOzDWgq6R8G3NDIthuBI4o5iKRjgaURMXsjYttkksZImiVp1rJlyypxSDMzs2avqaTfmew5+w15F+hU5HG+AHxV0gLgJrIfE5cA7SXVPSughuxJf6TPHgBp+3bAm4XlDeyzXkRcFREDI2Jg586diwzRzMysdWsq6S8B+jeyrR/ZE/qaFBE/iIiaiOhJNhHvvog4GbgfGJqqDQfuSMtT0jpp+30REan8pDS7fxegF/B4MTGYmZnlXVNJ//fAVZJ2LCxM61fQeNd/sf4d+J6k+WRj9tek8muAjqn8e8A5ABHxHNnjgJ8HpgJnRsSHmxmDmZlZLjT1GN4Lgf2AeZIeJ7vy70Y2Y35a2r5RIuIB4IG0/BINzL6PiH8A32hk/ws35bhmZmZ5t8Er/Yj4ICK+Snar3Axgdfr8akQcXzDz3szMzJq5ol64ExH3AveWORYzMzMro2Ifw2tmZmYtnJO+mZlZTjjpm5mZ5URRSV9S33IHYmZmZuVV1EQ+4E5JWwMPAw+mvyfTA3PMzMysBSj21bo7AZ8D/gT0Bf4ArJB0ZxljMzMzsxIq9kqfiHgpPQe/bfobAnQpV2BmZmZWWsWO6d8s6VXgOmBXsjfs9YwIv8vezMyshSh29v5+wDrgqfRXGxFvly0qMzMzK7lix/R7AQcC9wFfBP4qaa6k35YzODMzMyudou/Tj4glwBxgPrAA2AE4ujxhtS7/+Mc/GDRoEP369WPvvfdm/PjxAFx++eXsvvvuSOKNN95YX//FF1/kwAMPpF27dvz85z//WFunnnoqXbp0YZ999qnodzAzs5av2DH9KZKWk73vfj/gz8D+EdG9nMG1Fu3ateO+++7jqaeeora2lqlTpzJjxgy+8IUvcO+997Lzzjt/rH6HDh249NJL+f73v/+JtkaMGMHUqVMrFbqZmbUixc7evw0YGxEvlzOY1koS22yzDQAffPABH3zwAZIYMGBAg/W7dOlCly5d+Mtf/vKJbQcddBALFiwoZ7hmZtZKFTumfy2wSNKXJJ0IIGnr9MAeK8KHH35I//796dKlC0cccQSDBw+udkhmZpYzxXbv7wvMBa4GrknFBwMTyxRXq7PllltSW1vLokWLePzxx3n22WerHZKZmeVMsRP5rgB+HBG9gQ9S2YNkM/ltI7Rv355DDz3U4/JmZlZxxSb9vYEb0nIARMQa4DPlCKq1WbZsGStXrgTg3XffZdq0afTu3bvKUZmZWd4Um/QXAPsXFkgaRHb7njVhyZIlHHroofTt25fPfe5zHHHEERx77LFceuml1NTUsGjRIvr27cvo0aMBeO2116ipqeGiiy7iggsuoKamhrfeeguAYcOGceCBBzJnzhxqamq45pprNnRoMzOz9VTMi/IkHUs2ln8lMA64EDgdOC0i7ilrhJtp4MCBMWvWrGqHYWZmRbr54oeqHUKzduJ3D2qyjqTZETGwfnlRt+xFxJ2ShgCnkY3l7wx8PSJmF7O/pE8DDwHt0jFvjYjxknYBbgI6ArOBb0fE+5LakT3nf3/gTeDEiFiQ2voBMAr4EPi3iLi7mBg25FuXfPLWOPvIDWO/XO0QzMysBDbmLXtPAv+yicd5DzgsIlZL+hTwiKS/At8DLo6ImyRdSZbMr0ifKyJid0knAT8FTpTUBziJbI7BjsC9kvaIiA83MS4zM7PcaDTpS/pRRFyYls9vrF5E/Lipg0Q2hrA6rX4q/QVwGPDNVD4JOJcs6R+XlgFuBS6XpFR+U0S8B7wsaT4wCHi0qRjMzMzybkNX+jUFyz0aqdP0hIBE0pZkXfi7A78C/gasjIi1qcoioO6xvt2BhQARsVbSKrIhgO7AjIJmC/cpPNYYYAzATjvtVGyIZmZmrVqjST8izihYHrm5B0pd8P0ltQduB8p2z1pEXAVcBdlEvnIdx8zMrCUp9ol8f5L0jTQhb7NExErgfrJX9baXVPfDowZYnJYXk3oX0vbtyCb0rS9vYB8zMzPbgGLv038Q+L/A65ImSTpKUtGv5ZXUOV3hI+kzwBHAC2TJf2iqNpzsLX4AU9I6aft9aV7AFOAkSe3SzP9ewOPFxmFmZpZnxb5w5+KIGAQMBF4Cfgn8XdKlRR6nG3C/pKeBmcC0iLgT+Hfge2lCXkc+eq7/NUDHVP494JwUx3PALcDzwFTgTM/cNzMzK07Rt+wBRMQ84DxJfwJ+BpwJ/FsR+z0NfOI9shHxEtns+/rl/wC+0UhbF5I9HMjMzMw2wsZ00e8m6T8kPQdMA+aRvWnPzMzMWoCirvQlzQT2IBtT/z5Z9/zaDe9lZmZmzUmx3fs/A/4cEe+WMxgzMzMrn2In8t0CbCXp25LOBpC0o6SaJnY1MzOzZqLY+/QPBuYAJwP/mYp7kT0y18zMzFqAYify/ZLsTXdDgLqx/MdoYOa9mZmZNU/FJv2eETE9Ldc91vZ9NvKWPzMzM6ueYpP+85KOqlf2T8AzJY7HzMzMyqTYK/VxwJ2S/gJ8RtJvgK+QverWzMzMWoBiZ+/PAPoBzwETgZeBQRExs4yxmZmZWQkVPSYfEYuB/65bl7SvpIsjosHH5ZqZmVnzssErfUlbSfqJpD9LukjStpJ2lXQ78CiwtDJhmpmZ2eZq6kr/V2QvyrkbOBrYF+gNTAJOi4g3yhuemZmZlUpTSf8ooH9ELJV0GfAqcHBEPFz+0MzMzKyUmprIt01ELAWIiEXAaid8MzOzlqmpK/02kg4FVFdQfz0i7itTbGZmZlZCTSX9pWS36NV5s956ALuWOigzMzMrvQ0m/YjoWaE4zMzMrMyKfQyvmZmZtXBO+mZmZjnhpG9mZpYTFUn6knpIul/S85KekzQ2lXeQNE3SvPS5fSqXpEslzZf0tKT9CtoanurPkzS8EvGbmZm1BpW60l8LjIuIPsABwJmS+gDnANMjohcwPa1D9vS/XulvDHAFZD8SgPHAYGAQML7uh4KZmZltWEWSfkQsiYgn0vLbwAtAd7JX805K1SYBx6fl44DrIjMDaC+pG9kTAqdFxPKIWAFMA4ZU4juYmZm1dBUf05fUk+x5/o8BXSNiSdr0GtA1LXcHFhbstiiVNVZe/xhjJM2SNGvZsmUljd/MzKylqmjSl7QN8EfgOxHxVuG2iAiyh/1stoi4KiIGRsTAzp07l6JJMzOzFq9iSV/Sp8gS/o0RcVsqfj1125M+617VuxjoUbB7TSprrNzMzMyaUKnZ+wKuAV6IiIsKNk0B6mbgDwfuKCg/Jc3iPwBYlYYB7gaOlLR9msB3ZCozMzOzJjT17P1S+QLwbeAZSbWp7IfABOAWSaOAV4AT0ra7gGOA+cA7wEiAiFgu6SfAzFTv/IhYXpmvYGZm1rJVJOlHxCMUvJmvnsMbqB/AmY20NZGPv/THzMzMiuAn8pmZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlhJO+mZlZTjjpm5mZ5YSTvpmZWU446ZuZmeWEk76ZmVlOOOmbmZnlREWSvqSJkpZKeragrIOkaZLmpc/tU7kkXSppvqSnJe1XsM/wVH+epOGViN3MzKy1qNSV/rXAkHpl5wDTI6IXMD2tAxwN9Ep/Y4ArIPuRAIwHBgODgPF1PxTMzMysaRVJ+hHxELC8XvFxwKS0PAk4vqD8usjMANpL6gYcBUyLiOURsQKYxid/SJiZmVkjqjmm3zUilqTl14Cuabk7sLCg3qJU1lj5J0gaI2mWpFnLli0rbdRmZmYtVLOYyBcRAUQJ27sqIgZGxMDOnTuXqlkzM7MWrZpJ//XUbU/6XJrKFwM9CurVpLLGys3MzKwI1Uz6U4C6GfjDgTsKyk9Js/gPAFalYYC7gSMlbZ8m8B2ZyszMzKwIbSpxEEmTgUOATpIWkc3CnwDcImkU8ApwQqp+F3AMMB94BxgJEBHLJf0EmJnqnR8R9ScHmpmZWSMqkvQjYlgjmw5voG4AZzbSzkRgYglDMzMzy41mMZHPzMzMys9J38zMLCec9M3MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcsJJ38zMLCec9M3MzHLCSd/MzCwnnPTNzJqpU089lS5durDPPvusLzv33HPp3r07/fv3p3///tx1110AvP/++4wcOZJ9992Xfv368cADD1QpamvOnPTNzJqpESNGMHXq1E+Uf/e736W2tpba2lqOOeYYAK6++moAnnnmGaZNm8a4ceNYt25dReO15s9J38ysmTrooIPo0KFDUXWff/55DjvsMAC6dOlC+/btmTVrVjnDsxbISd/MSmLlypUMHTqU3r17s9dee/Hoo48CcNlll9G7d2/23ntvzj777CpH2Tpcfvnl9O3bl1NPPZUVK1YA0K9fP6ZMmcLatWt5+eWXmT17NgsXLqxypNbcOOlbq0EkKm4AAAkGSURBVNfQuOiJJ564fky0Z8+e9O/fv4oRtg5jx45lyJAhvPjiizz11FPstdde3H///dxxxx089dRTPPfcc3z/+9+vdpgt3hlnnMHf/vY3amtr6datG+PGjQOy/89ramoYOHAg3/nOd/j85z/PlltuWeVorblpU+0AzMptxIgRnHXWWZxyyinry26++eb1y+PGjWO77barRmitxqpVq3jooYe49tprAWjbti1t27bliiuu4JxzzqFdu3ZA1u1sm6dr167rl0877TSOPfZYANq0acPFF1+8ftvnP/959thjj4rHZ82br/St1dvQuGhEcMsttzBs2LAKR9W6vPzyy3Tu3JmRI0cyYMAARo8ezZo1a5g7dy4PP/wwgwcP5uCDD2bmzJnVDrXFW7Jkyfrl22+/fX0P1jvvvMOaNWsAmDZtGm3atKFPnz5VidGaL1/pW649/PDDdO3alV69elU7lBZt7dq1PPHEE1x22WUMHjyYsWPHMmHCBNauXcvy5cuZMWMGM2fO5IQTTuCll15CUrVDbhGGDRvGAw88wBtvvEFNTQ3nnXceDzzwALW1tUiiZ8+e/OY3vwFg6dKlHHXUUWyxxRZ0796d66+/vsrRW3PkpG+5NnnyZF/ll0BNTQ01NTUMHjwYgKFDhzJhwgRqamr4+te/jiQGDRrEFltswRtvvEHnzp2rHHHLMHny5E+UjRo1qsG6PXv2ZM6cOeUOyVo4J33LrbVr13Lbbbcxe/bsaofS4u2www706NGDOXPmsOeeezJ9+nT69OnDbrvtxv3338+hhx7K3Llzef/99+nUqVO1w90ss08bU+0QmrX9r76q2iHYBjjpW27de++99O7dm5qammqH0ipcdtllnHzyybz//vvsuuuu/O53v2Prrbfm1FNPZZ999qFt27ZMmjTJXftmVdQik76kIcAlwJbAbyNiQpVDsmasoXHRUaNGcdNNN7lrv4T69+/f4MNgbrjhhipEY2YNaXFJX9KWwK+AI4BFwExJUyLi+epGZs1VQ+OiwPrby1qTU28+tdohNFsTT5xY7RDMqq7FJX1gEDA/Il4CkHQTcBzgpN/MvXb1idUOodna4bSbm65kZraZFBHVjmGjSBoKDImI0Wn928DgiDiroM4YoG62zZ5AS5vS2gl4o9pBtHI+x5Xh81x+Psfl1xLP8c4R8YnbZFrilX6TIuIqoMVOIZU0KyIGVjuO1sznuDJ8nsvP57j8WtM5bolP5FsM9ChYr0llZmZmtgEtMenPBHpJ2kVSW+AkYEqVYzIzM2v2Wlz3fkSslXQWcDfZLXsTI+K5KodVai12aKIF8TmuDJ/n8vM5Lr9Wc45b3EQ+MzMz2zQtsXvfzMzMNoGTvpmZWU446VeJpImSlkp6tpHtknSppPmSnpa0X6VjbOkk9ZB0v6TnJT0naWwDdXyeN4OkT0t6XNJT6Ryf10CddpJuTuf4MUk9Kx9pyydpS0lPSrqzgW0+xyUgaYGkZyTVSvrEM6Vbw78XTvrVcy0wZAPbjwZ6pb8xwBUViKm1WQuMi4g+wAHAmZL61Kvj87x53gMOi4h+QH9giKQD6tUZBayIiN2Bi4GfVjjG1mIs8EIj23yOS+fQiOjfyH35Lf7fCyf9KomIh4DlG6hyHHBdZGYA7SV1q0x0rUNELImIJ9Ly22T/YHavV83neTOk87Y6rX4q/dWfHXwcMCkt3wocLr9qb6NIqgG+DPy2kSo+x5XR4v+9cNJvvroDCwvWF/HJhGVFSt2dA4DH6m3yed5Mqdu5FlgKTIuIRs9xRKwFVgEdKxtli/dL4GxgXSPbfY5LI4B7JM1Oj3Ovr8X/e+Gkb62epG2APwLfiYi3qh1PaxMRH0ZEf7KnYw6StE+1Y2pNJB0LLI2I2dWOJQe+GBH7kXXjnynpoGoHVGpO+s2XHzdcApI+RZbwb4yI2xqo4vNcIhGxErifT85VWX+OJbUBtgPerGx0LdoXgK9KWgDcBBwm6YZ6dXyOSyAiFqfPpcDtZG91LdTi/71w0m++pgCnpNmiBwCrImJJtYNqSdKY5jXACxFxUSPVfJ43g6TOktqn5c8ARwAv1qs2BRielocC94WfCla0iPhBRNRERE+yx47fFxHfqlfN53gzSdpa0mfrloEjgfp3V7X4fy9a3GN4WwtJk4FDgE6SFgHjySZBERFXAncBxwDzgXeAkdWJtEX7AvBt4Jk05gzwQ2An8HkukW7AJElbkl1E3BIRd0o6H5gVEVPIfnhdL2k+2eTVk6oXbuvhc1xyXYHb0/zHNsDvI2KqpNOh9fx74cfwmpmZ5YS7983MzHLCSd/MzCwnnPTNzMxywknfzMwsJ5z0zczMcsJJ38zMLCec9M2sSZK+KOl/Ja2StFzS/0j6nKQRkh6pdnxmVhw/nMfMNkjStsCdwBnALUBb4Etkr9Xd3LbbpBfEmFkF+ErfzJqyB0BETE4v13k3Iu4BPgCuBA6UtFrSSgBJX5b0pKS3JC2UdG5dQ5J6SgpJoyS9Ctwn6dOSbpD0pqSVkmZK6lqF72nW6jnpm1lT5gIfSpok6WhJ2wNExAvA6cCjEbFNRLRP9dcApwDtyd4Bf4ak4+u1eTCwF3AU2TPjtyN7kUnH1Oa7Zf5OZrnkpG9mG5ReR/xFsneNXw0skzSlsavxiHggIp6JiHUR8TQwmSzJFzo3ItZExLtkPQYdgd1TT8JsvwLZrDyc9M2sSRHxQkSMiIgaYB9gR+CXDdWVNFjS/ZKWSVpFduXeqV61hQXL1wN3AzdJ+ruk/06vRDazEnPSN7ONEhEvAteSJf+G3tj1e7JXkPaIiO3Ixv1Vv5mC9j6IiPMiog/weeBYsuEBMysxJ30z2yBJvSWNk1ST1nsAw4AZwOtAjaS2Bbt8FlgeEf+QNAj4ZhPtHypp3/R63rfIuvvXleO7mOWdk76ZNeVtYDDwmKQ1ZMn+WWAccB/wHPCapDdS/X8Bzpf0NvBjstv8NmQH4FayhP8C8CBZl7+ZlZgiGuqdMzMzs9bGV/pmZmY54aRvZmaWE076ZmZmOeGkb2ZmlhNO+mZmZjnhpG9mZpYTTvpmZmY54aRvZmaWE/8fu33usj4hRjAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeGz8FVL0WgO",
        "colab_type": "text"
      },
      "source": [
        "The original dataset is quite polarized. After filtering, the distribution shape is preserved. "
      ]
    }
  ]
}